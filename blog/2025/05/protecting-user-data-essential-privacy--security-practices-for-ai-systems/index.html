<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Protecting User Data: Essential Privacy &amp; Security
Practices for AI Systems – Common Sense Systems</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Learn the critical best practices
for safeguarding user data in AI systems while maintaining compliance
with global regulations like GDPR.">
  <meta name="author" content="Common Sense Systems, Inc.">
  <meta name="date" content="2025-05-09">
  <meta name="categories" content="AI for Business, Data Analytics">
  <meta name="tags" content="AI, Data Security, Technology Adoption,
Digital Strategy, Integration, Efficiency">
  <link rel="stylesheet" href="/css/styles.css">
  <link rel="icon" type="image/png" href="/assets/favicon/favicon-96x96.png" />
  <style>
    /* Blog post specific styles */
    .blog-post {
      margin: 2rem 0;
    }

    .blog-header {
      margin-bottom: 2rem;
    }

    .blog-title {
      font-size: 2.5rem;
      margin-bottom: 0.5rem;
    }

    .blog-meta {
      color: #666;
      margin-bottom: 1rem;
      font-size: 0.9rem;
    }

    .blog-meta span:not(:last-child):after {
      content: "•";
      margin: 0 0.5rem;
    }

    .blog-content {
      line-height: 1.7;
    }

    .blog-tags {
      margin-top: 2rem;
    }

    .blog-tag {
      background-color: #f0f0f0;
      padding: 0.4rem 0.6rem;
      border-radius: 4px;
      font-size: 0.9rem;
      color: #333;
      text-decoration: none;
      display: inline-block;
      margin-right: 0.5rem;
      margin-bottom: 0.5rem;
    }

    /* Code blocks */
    pre {
      background-color: #f5f5f5;
      padding: 1rem;
      border-radius: 4px;
      overflow-x: auto;
    }

    code {
      font-family: 'Courier New', Courier, monospace;
    }

    /* Images */
    .blog-content img {
      max-width: 100%;
      height: auto;
      margin: 1.5rem 0;
      border-radius: 4px;
    }

    /* Blockquotes */
    blockquote {
      border-left: 4px solid #0066cc;
      padding-left: 1rem;
      margin-left: 0;
      color: #333;
      font-style: italic;
    }
  </style>

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "Protecting User Data: Essential Privacy & Security Practices for AI Systems",
    "description": "Learn the critical best practices for safeguarding user data in AI systems while maintaining compliance with global regulations like GDPR.",
    "image": "assets/header-image.png",
    "datePublished": "2025-05-09",
    "author": {
      "@type": "Organization",
      "name": "Common Sense Systems, Inc."
    },
    "publisher": {
      "@type": "Organization",
      "name": "Common Sense Systems, Inc.",
      "logo": {
        "@type": "ImageObject",
        "url": "assets/header-image.png"
      }
    },
    "mainEntityOfPage": {
      "@type": "WebPage"
    },
    "keywords": [
      "AI",
      "Data Security",
      "Technology Adoption",
      "Digital Strategy",
      "Integration",
      "Efficiency"
    ],
    "articleSection": "AI for Business, Data Analytics",
    "articleBody": "Introduction: The Data Privacy Imperative in AI Development... [full content]"
  }
  </script>

</head>
<body>

  <!-- SITE HEADER / NAVIGATION -->
  <header>
    <div class="container">
      <nav>
        <a href="/index.html" class="logo">
          <span>Common Sense Systems, Inc.</span>
        </a>
        <ul class="nav-links">
          <li><a href="/index.html">Home</a></li>
          <li><a href="/index.html#services">Services</a></li>
          <li><a href="/blog/index.html" class="active">Blog</a></li>
          <li><a href="/contact.html">Contact</a></li>
        </ul>
        <div class="menu-toggle">
          <span></span><span></span><span></span>
        </div>
      </nav>
    </div>
  </header>

  <!-- BLOG POST CONTENT -->
  <main class="container">
    <article class="blog-post">
      <div class="blog-header">
        <h1 class="blog-title">Protecting User Data: Essential Privacy
&amp; Security Practices for AI Systems</h1>
        <div class="blog-meta">
          <span class="blog-date">2025-05-09</span>
          <span class="blog-author">Common Sense Systems, Inc.</span>
                    <span class="blog-categories">AI for Business, Data
Analytics</span>
                  </div>
      </div>

            <div class="featured-image">
        <img src="assets/header-image.png" alt="Protecting User Data:
Essential Privacy &amp; Security Practices for AI Systems">
      </div>
      
      <div class="blog-content">
        <h2
        id="introduction-the-data-privacy-imperative-in-ai-development">Introduction:
        The Data Privacy Imperative in AI Development</h2>
        <p>In today’s data-driven world, artificial intelligence has
        become a transformative force across industries. However, this
        technological revolution comes with significant
        responsibilities, particularly regarding the protection of user
        data. As AI systems increasingly process sensitive personal
        information to deliver personalized experiences and insights,
        the imperative to implement robust privacy and security measures
        has never been more critical.</p>
        <p>Recent statistics highlight the urgency of this challenge:
        according to IBM’s Cost of a Data Breach Report, the average
        cost of a data breach reached $4.45 million in 2023, with
        AI-powered systems presenting unique vulnerabilities due to
        their data-hungry nature. For organizations implementing AI
        solutions, protecting user data isn’t just a regulatory
        requirement—it’s a business imperative that directly impacts
        customer trust, brand reputation, and ultimately, the bottom
        line.</p>
        <p>This guide explores the essential best practices for AI
        privacy and security, providing actionable insights for
        developers, data scientists, and business leaders navigating the
        complex landscape of responsible AI implementation. Whether
        you’re building machine learning models, deploying natural
        language processing tools, or integrating AI into existing
        business processes, these principles will help you protect
        sensitive data while maximizing the value of your AI
        investments.</p>
        <h2 id="the-unique-privacy-challenges-of-ai-systems">The Unique
        Privacy Challenges of AI Systems</h2>
        <h3 id="data-hunger-and-collection-risks">Data Hunger and
        Collection Risks</h3>
        <p>AI systems, particularly those powered by machine learning,
        require substantial amounts of data to function effectively.
        This “data hunger” creates inherent privacy risks:</p>
        <ul>
        <li><strong>Excessive Data Collection</strong>: AI systems often
        gather more data than necessary, creating larger attack surfaces
        and increasing privacy risks</li>
        <li><strong>Persistent Storage</strong>: Training data may be
        stored indefinitely, increasing the likelihood of exposure over
        time</li>
        <li><strong>Hidden Inferences</strong>: AI can derive sensitive
        attributes not explicitly provided in the original dataset</li>
        <li><strong>Re-identification Risks</strong>: Even “anonymized”
        data can often be re-identified when combined with other
        datasets</li>
        </ul>
        <h3 id="model-vulnerabilities">Model Vulnerabilities</h3>
        <p>The models themselves present unique security challenges:</p>
        <ul>
        <li><strong>Model Inversion Attacks</strong>: Sophisticated
        attackers can reverse-engineer training data from model
        outputs</li>
        <li><strong>Membership Inference</strong>: Techniques that can
        determine if specific data was used to train a model</li>
        <li><strong>Data Poisoning</strong>: Malicious actors can
        contaminate training data to manipulate model behavior</li>
        <li><strong>Adversarial Examples</strong>: Specially crafted
        inputs that cause AI systems to make predictable mistakes</li>
        </ul>
        <blockquote>
        <p>“The most significant AI privacy risks often stem not from
        malicious attacks but from poor design choices made during
        development. Building privacy into AI systems from the ground up
        is always more effective than attempting to retrofit protections
        later.” — AI Security Research Consortium</p>
        </blockquote>
        <p>For businesses implementing AI solutions, understanding these
        unique challenges is the first step toward effective mitigation.
        If you’re concerned about potential vulnerabilities in your AI
        implementations, Common Sense Systems can help you identify and
        address these risks before they impact your operations or
        customers.</p>
        <h2
        id="essential-data-protection-strategies-for-ai-systems">Essential
        Data Protection Strategies for AI Systems</h2>
        <h3 id="data-minimization-and-purpose-limitation">Data
        Minimization and Purpose Limitation</h3>
        <p>One of the most effective privacy protection strategies is
        simply using less data:</p>
        <ol type="1">
        <li><strong>Collect Only What’s Necessary</strong>: Identify the
        minimum data required for your AI system to function
        effectively</li>
        <li><strong>Implement Clear Purpose Limitations</strong>: Define
        specific purposes for data collection and use, and adhere to
        these boundaries</li>
        <li><strong>Regular Data Audits</strong>: Periodically review
        data holdings to identify and purge unnecessary information</li>
        <li><strong>Differential Privacy</strong>: Consider implementing
        differential privacy techniques that add calibrated noise to
        datasets while preserving analytical utility</li>
        </ol>
        <h3 id="robust-anonymization-techniques">Robust Anonymization
        Techniques</h3>
        <p>While perfect anonymization is increasingly difficult, these
        techniques significantly reduce re-identification risks:</p>
        <ul>
        <li><strong>K-anonymity</strong>: Ensuring that each record is
        indistinguishable from at least k-1 other records</li>
        <li><strong>Generalization</strong>: Replacing specific values
        with broader categories (e.g., exact age with age ranges)</li>
        <li><strong>Perturbation</strong>: Adding controlled noise to
        numerical values</li>
        <li><strong>Synthetic Data Generation</strong>: Creating
        artificial data that maintains statistical properties without
        containing real user information</li>
        </ul>
        <h3 id="encryption-and-access-controls">Encryption and Access
        Controls</h3>
        <p>Protecting data both at rest and in transit is
        fundamental:</p>
        <ul>
        <li><strong>End-to-End Encryption</strong>: Implement strong
        encryption for data transfers between system components</li>
        <li><strong>Homomorphic Encryption</strong>: Consider emerging
        techniques that allow computation on encrypted data</li>
        <li><strong>Secure Enclaves</strong>: Use trusted execution
        environments for sensitive processing</li>
        <li><strong>Granular Access Controls</strong>: Implement the
        principle of least privilege, giving users and systems access
        only to the data they absolutely need</li>
        </ul>
        <div class="sourceCode" id="cb1"><pre
        class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of implementing differential privacy in Python using the IBM diffprivlib</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> diffprivlib <span class="im">import</span> mechanisms</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Original sensitive data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>sensitive_data <span class="op">=</span> np.array([<span class="dv">23</span>, <span class="dv">45</span>, <span class="dv">67</span>, <span class="dv">32</span>, <span class="dv">56</span>, <span class="dv">78</span>, <span class="dv">90</span>, <span class="dv">12</span>])</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply Laplace mechanism with epsilon=0.5 (privacy budget)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>laplace <span class="op">=</span> mechanisms.Laplace(epsilon<span class="op">=</span><span class="fl">0.5</span>, sensitivity<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>protected_data <span class="op">=</span> np.array([laplace.randomise(x) <span class="cf">for</span> x <span class="kw">in</span> sensitive_data])</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Original data:&quot;</span>, sensitive_data)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Privacy-protected data:&quot;</span>, protected_data)</span></code></pre></div>
        <p>Implementing these strategies requires thoughtful planning
        and technical expertise. At Common Sense Systems, we specialize
        in helping businesses implement privacy-preserving AI solutions
        that balance protection with performance.</p>
        <h2
        id="regulatory-compliance-navigating-the-complex-landscape">Regulatory
        Compliance: Navigating the Complex Landscape</h2>
        <h3 id="key-regulations-impacting-ai-privacy">Key Regulations
        Impacting AI Privacy</h3>
        <p>AI systems must comply with an evolving patchwork of privacy
        regulations:</p>
        <ul>
        <li><strong>GDPR (European Union)</strong>: Requires explicit
        consent, data minimization, and provides “right to explanation”
        for automated decisions</li>
        <li><strong>CCPA/CPRA (California)</strong>: Gives consumers
        rights to know, delete, and opt-out of sales of their personal
        information</li>
        <li><strong>HIPAA (US Healthcare)</strong>: Strict requirements
        for handling protected health information in AI
        applications</li>
        <li><strong>AI-Specific Regulations</strong>: Emerging
        frameworks like the EU AI Act that classify AI systems by risk
        level</li>
        </ul>
        <h3 id="practical-compliance-measures">Practical Compliance
        Measures</h3>
        <p>To meet these regulatory requirements, consider these
        practical steps:</p>
        <ol type="1">
        <li><strong>Data Protection Impact Assessments (DPIAs)</strong>:
        Conduct thorough risk assessments before deploying AI systems
        that process personal data</li>
        <li><strong>Transparent Privacy Policies</strong>: Clearly
        communicate how AI systems use data in accessible language</li>
        <li><strong>Consent Management</strong>: Implement robust
        mechanisms for obtaining and managing user consent</li>
        <li><strong>Data Subject Rights Management</strong>: Build
        processes to handle access, deletion, and portability
        requests</li>
        <li><strong>Documentation</strong>: Maintain detailed records of
        data processing activities, model training procedures, and
        testing results</li>
        </ol>
        <table>
        <colgroup>
        <col style="width: 17%" />
        <col style="width: 37%" />
        <col style="width: 44%" />
        </colgroup>
        <thead>
        <tr>
        <th>Regulation</th>
        <th>Key Requirements for AI</th>
        <th>Penalties for Non-Compliance</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td>GDPR</td>
        <td>Lawful basis for processing, data minimization, right to
        explanation</td>
        <td>Up to €20M or 4% of global revenue</td>
        </tr>
        <tr>
        <td>CCPA/CPRA</td>
        <td>Disclosure requirements, opt-out rights, service provider
        contracts</td>
        <td>$2,500-$7,500 per intentional violation</td>
        </tr>
        <tr>
        <td>HIPAA</td>
        <td>Business associate agreements, security safeguards, breach
        notification</td>
        <td>Up to $1.5M per violation category annually</td>
        </tr>
        <tr>
        <td>EU AI Act</td>
        <td>Risk-based classification, conformity assessments for
        high-risk AI</td>
        <td>Up to €30M or 6% of global revenue</td>
        </tr>
        </tbody>
        </table>
        <p>Staying compliant with these regulations requires ongoing
        vigilance and adaptation as both technology and legal
        requirements evolve. This complexity is why many organizations
        partner with specialists who understand both the technical and
        regulatory dimensions of AI privacy.</p>
        <h2 id="privacy-preserving-ai-architectures">Privacy-Preserving
        AI Architectures</h2>
        <h3 id="federated-learning">Federated Learning</h3>
        <p>Federated learning represents a paradigm shift in how AI
        models are trained:</p>
        <ul>
        <li><strong>Local Processing</strong>: Models are trained on
        user devices without raw data ever leaving them</li>
        <li><strong>Aggregated Updates</strong>: Only model updates, not
        raw data, are sent to central servers</li>
        <li><strong>Reduced Data Exposure</strong>: Dramatically reduces
        privacy risks by keeping sensitive data local</li>
        <li><strong>Implementation Challenges</strong>: Requires careful
        design to prevent leakage through model updates</li>
        </ul>
        <h3 id="secure-multi-party-computation">Secure Multi-Party
        Computation</h3>
        <p>This cryptographic approach enables collaborative analysis
        without data sharing:</p>
        <ul>
        <li><strong>Shared Computation Without Shared Data</strong>:
        Multiple parties can jointly analyze data without revealing
        their inputs</li>
        <li><strong>Cryptographic Guarantees</strong>: Mathematical
        assurances that private data remains protected</li>
        <li><strong>Computational Overhead</strong>: Typically requires
        more processing power than traditional approaches</li>
        <li><strong>Growing Ecosystem</strong>: Increasingly practical
        with modern tools and frameworks</li>
        </ul>
        <h3 id="privacy-enhancing-technologies-pets">Privacy-Enhancing
        Technologies (PETs)</h3>
        <p>Several emerging technologies are making privacy-preserving
        AI more practical:</p>
        <ul>
        <li><strong>Zero-Knowledge Proofs</strong>: Verify properties of
        data without revealing the data itself</li>
        <li><strong>Trusted Execution Environments</strong>:
        Hardware-protected regions for sensitive computations</li>
        <li><strong>Confidential Computing</strong>: Cloud-based
        processing that keeps data encrypted even during
        computation</li>
        <li><strong>Synthetic Data</strong>: AI-generated datasets that
        maintain statistical properties without containing real user
        information</li>
        </ul>
        <blockquote>
        <p>“Privacy-preserving AI isn’t just about compliance—it’s about
        building sustainable AI systems that maintain user trust while
        delivering business value. The organizations that master this
        balance will have a significant competitive advantage.” —
        Journal of AI Ethics</p>
        </blockquote>
        <h2 id="case-studies-privacy-preserving-ai-in-action">Case
        Studies: Privacy-Preserving AI in Action</h2>
        <h3
        id="healthcare-collaborative-research-without-data-sharing">Healthcare:
        Collaborative Research Without Data Sharing</h3>
        <p>A consortium of hospitals needed to develop AI diagnostic
        tools without sharing sensitive patient records. Their
        solution:</p>
        <ul>
        <li>Implemented federated learning across five hospital
        systems</li>
        <li>Trained diagnostic models that outperformed individual
        hospital models by 23%</li>
        <li>Maintained full HIPAA compliance with no patient data ever
        leaving local systems</li>
        <li>Reduced diagnostic errors by 17% compared to previous
        methods</li>
        </ul>
        <h3
        id="financial-services-fraud-detection-with-privacy-guarantees">Financial
        Services: Fraud Detection with Privacy Guarantees</h3>
        <p>A financial services company needed to improve fraud
        detection without exposing customer transaction data:</p>
        <ul>
        <li>Developed a secure multi-party computation system across
        multiple banks</li>
        <li>Identified cross-institutional fraud patterns previously
        impossible to detect</li>
        <li>Reduced false positives by 34% while increasing fraud
        detection by 27%</li>
        <li>Maintained full regulatory compliance across multiple
        jurisdictions</li>
        </ul>
        <h3
        id="retail-personalization-without-privacy-compromise">Retail:
        Personalization Without Privacy Compromise</h3>
        <p>A retail chain wanted to offer personalized recommendations
        without creating privacy risks:</p>
        <ul>
        <li>Implemented on-device processing for sensitive customer
        preference data</li>
        <li>Used differential privacy techniques to protect aggregated
        insights</li>
        <li>Created synthetic training data that preserved shopping
        patterns without individual identifiers</li>
        <li>Increased conversion rates by 18% while reducing customer
        privacy complaints</li>
        </ul>
        <p>These examples demonstrate that with thoughtful architecture
        and implementation, organizations can achieve both powerful AI
        capabilities and strong privacy protections.</p>
        <h2 id="building-a-privacy-first-ai-culture">Building a
        Privacy-First AI Culture</h2>
        <p>Technical solutions alone aren’t sufficient—organizations
        need to build privacy into their culture:</p>
        <ol type="1">
        <li><strong>Privacy by Design</strong>: Make privacy a core
        requirement from the earliest stages of AI development</li>
        <li><strong>Cross-Functional Teams</strong>: Include privacy
        experts, legal counsel, and ethicists in AI development
        teams</li>
        <li><strong>Regular Training</strong>: Ensure all team members
        understand privacy principles and their application to AI</li>
        <li><strong>Incentive Alignment</strong>: Reward
        privacy-preserving innovations alongside performance
        improvements</li>
        <li><strong>Ethical Review Processes</strong>: Establish formal
        review procedures for high-risk AI applications</li>
        <li><strong>Transparency Commitments</strong>: Be open with
        users about how their data is used and protected</li>
        </ol>
        <p>By embedding these principles throughout your organization,
        privacy becomes a competitive advantage rather than a compliance
        burden.</p>
        <h2
        id="conclusion-the-future-of-privacy-preserving-ai">Conclusion:
        The Future of Privacy-Preserving AI</h2>
        <p>As AI systems become more powerful and ubiquitous, the
        importance of privacy-preserving approaches will only increase.
        Organizations that master these techniques will build stronger
        customer trust, reduce regulatory risks, and create more
        sustainable AI implementations.</p>
        <p>The good news is that privacy and utility are not
        fundamentally opposed. With the right approaches—from federated
        learning to differential privacy to synthetic data—organizations
        can achieve remarkable AI capabilities while maintaining strong
        privacy protections. The key is approaching privacy not as an
        afterthought but as a fundamental design principle.</p>
        <p>For businesses navigating these complex waters, expert
        guidance can make all the difference. At Common Sense Systems,
        we specialize in helping organizations implement AI solutions
        that respect user privacy while delivering business value.
        Whether you’re just beginning your AI journey or looking to
        enhance the privacy protections in existing systems, we can help
        you build responsible, effective AI implementations.</p>
        <p>By embracing privacy-preserving AI practices today, you’re
        not just meeting current requirements—you’re future-proofing
        your organization for a world where data protection will only
        become more critical.</p>
      </div>

            <div class="blog-tags">
                <a href="/blog/index.html?tags=AI, Data Security,
Technology Adoption, Digital Strategy, Integration,
Efficiency" class="blog-tag">AI, Data Security, Technology Adoption,
Digital Strategy, Integration, Efficiency</a>
              </div>
          </article>

    <!-- RELATED POSTS (if available) -->
    
    <!-- CTA Section -->
    <section class="cta">
      <div class="container">
        <h2>Ready to Transform Your Business?</h2>
        <p>Let's discuss how our process automation and AI solutions can help you achieve your business goals.</p>
        <a href="/contact.html" class="btn">Schedule a Consultation</a>
      </div>
    </section>
  </main>

  <!-- FOOTER -->
  <footer>
    <div class="container">
      <div class="footer-grid">
        <div class="footer-company">
          <h3>Common Sense Systems, Inc.</h3>
          <p>We help businesses leverage automation and AI to work smarter, optimize processes, and achieve sustainable growth.</p>
        </div>
        <div class="footer-links">
          <h4>Company</h4>
          <ul>
            <li><a href="/about.html">About Us</a></li>
            <li><a href="/team.html">Team</a></li>
            <li><a href="/payments.html">Payments</a></li>
          </ul>
        </div>
        <div class="footer-links">
          <h4>Services</h4>
          <ul>
            <li><a href="/ai-integration.html">AI Integration</a></li>
            <li><a href="/process-automation.html">Process Automation</a></li>
            <li><a href="/revenue-improvement.html">Revenue Improvement</a></li>
            <li><a href="/consulting.html">Consulting</a></li>
          </ul>
        </div>
        <div class="footer-links">
          <h4>Contact</h4>
          <ul>
            <li><a href="mailto:contact@common-sense.com">contact@common-sense.com</a></li>
            <li><a href="tel:+14259792282">Main: (425) 979-2282</a></li>
            <li><a href="tel:+14255019074">John: (425) 501-9074</a></li>
            <li><a href="https://maps.google.com/?q=11227+NE+128+ST,+Unit+I-102,+Kirkland,+WA+98034">11227 NE 128 St, Unit I-102, Kirkland, WA 98034</a></li>
          </ul>
        </div>
      </div>
      <div class="footer-bottom">
        <p>&copy; 1996-2025 Common Sense Systems, Inc. All rights reserved.</p>
      </div>
    </div>
  </footer>

  <!-- Basic JavaScript for mobile menu toggle -->
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const menuToggle = document.querySelector('.menu-toggle');
      const navLinks = document.querySelector('.nav-links');

      if (menuToggle) {
        menuToggle.addEventListener('click', function() {
          navLinks.classList.toggle('active');
          menuToggle.classList.toggle('active');
        });
      }
    });
  </script>
</body>
</html>
