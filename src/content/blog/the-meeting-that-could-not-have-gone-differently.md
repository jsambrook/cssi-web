---
title: 'The Meeting That Could Not Have Gone Differently'
description: 'Why good people in well-run hospitals still end up in the wrong conversation, and what a structural fix might look like.'
metaTitle: 'The Meeting Could Not Have Gone Differently | CSSI, Kirkland, WA'
metaDescription: 'Hospital boards drift toward institutional consensus over community advocacy. The cause is structural, not personal. AI might offer a new kind of counterweight.'
date: 2026-02-26
author: 'John Sambrook'
tags: ['Healthcare', 'Systems', 'AI', 'Strategy', 'Leadership']
imageAlt: 'Infographic showing the co-optation cycle in hospital governance and how AI could serve as a structural counterweight for community interests'
---

## TL;DR

Hospital governance suffers from a structural problem called co-optation: oversight boards gradually adopt the institutional perspective of the organizations they govern. This happens to good people doing their best. The usual remedies don't work because the cause is structural, not personal. AI may offer something new -- a persistent, dispassionate voice representing the community interest that currently has no advocate in the room.

---

<img src="/images/content/hospital-governance-cooptation-cycle.png" alt="Infographic showing the co-optation cycle in hospital governance: community elects part-time commissioners, commissioners depend on executives for information, departments advocate for more resources, board optimizes for smooth governance, and community interest loses its voice â€” with AI as the missing counterweight" width="1408" height="768" loading="lazy" decoding="async" />

I sat in a community hospital board meeting recently and watched three clinical departments present their growth strategies to the commissioners. Cardiology. Musculoskeletal. Gastroenterology. Each department had done its homework. Each had data. Each had a clear message for the board: we need more space.

One commissioner, a physician himself, asked a sharp question. He wanted to know about utilization -- specifically, how much the existing cath lab was actually being used. The answer was revealing. The cath lab sits empty most evenings, most of Saturday, and all of Sunday. A multimillion-dollar clinical space, dark for roughly three-quarters of every week.

The meeting moved on. The conversation stayed on space.

Nobody in that room was being dishonest. Nobody had a hidden agenda. Three departments genuinely believed that space was their binding constraint, and the commissioners genuinely wanted to support clinical growth. Everyone was acting in good faith. And yet the conversation that needed to happen -- about staffing models, scheduling patterns, and the actual utilization of existing capacity -- never quite materialized.

I left the meeting thinking: it could not have gone differently. Not with these people, who are among the most civic-minded and responsible I've encountered. Not with this structure. The outcome was baked in before anyone sat down.

## What happened is not a mystery

There is an old and well-documented dynamic in governance called co-optation. The sociologist Philip Selznick identified it in 1949 while studying the Tennessee Valley Authority.[^1] He observed that when governing boards depend on the cooperation of powerful groups, those groups gradually get absorbed into the decision-making process. The board's independence erodes -- not through corruption, not through bad faith, but through the ordinary mechanics of working relationships. Selznick defined co-optation as "the process of absorbing new elements into the leadership or policy-determining structure of an organization as a means of averting threats to its stability or existence."[^2]

In a community hospital, the mechanics look like this. Commissioners are part-time, often volunteer or modestly compensated, elected by a community that mostly does not pay attention to hospital governance. They depend on executives for information. They depend on physicians for clinical judgment. They depend on nurses and staff for the institution to function at all. The information asymmetry is massive -- a classic principal-agent problem,[^3] where the community (the principal) delegates authority to commissioners (agents), who in turn depend on executives and physicians (sub-agents). At each layer, the agent's interests can drift from the principal's. When a cardiologist says the department needs more space, most commissioners lack the independent analytical capability to challenge the claim.

Over time -- and this is Selznick's key insight -- the commissioners optimize for smooth governance rather than aggressive community advocacy. They approve capital projects, staffing expansions, and compensation packages because the people they trust and work with closely tell them these things are necessary. And individually, each decision might be defensible. It is the cumulative drift that costs the community.

None of this is a story about bad people. The commissioners I've observed are dedicated, thoughtful, and genuinely trying to serve the public interest. The executives are competent and mission-driven. The physicians care about their patients. The nurses are stretched thin and doing remarkable work. Every person in that room is doing their best within a structure that produces a predictable result.

And it isn't limited to the boardroom. I've done [analytical work on collective bargaining agreements](/insights/nursing-conflict) between Washington State hospitals and the nurses' union, and found the same structural pattern in a different form. Every single agreement contained embedded conflicts -- situations where the contract itself places people in impossible positions. Scheduling flexibility vs. income security. Operational needs vs. contractual protections. Management and labor locked in a relationship that neither side would design from scratch but neither side can unilaterally change.

As someone who has lived a long life, I know that I would not want to be in a long-term relationship with people who didn't want the best for me or who were constantly antagonistic. That is how I read the management-nursing union dynamic at many hospitals: not as a story of bad actors, but as a system design problem. If it were solvable within the current structure, it would have been solved sometime in the last fifty years.

## Goldratt's principle

My mentor, Eli Goldratt, the creator of Theory of Constraints, drilled one idea into everyone he taught: the problems you find will be system conflicts, not the result of bad people.[^4] If the system produces an undesirable outcome reliably, the answer is in the system's design, not in replacing the people who operate it.

This applies directly. If every community hospital board in the country exhibits some version of the same drift toward institutional consensus -- and the governance literature suggests they do -- then the problem is not that we have the wrong commissioners. The problem is that the structure lacks a counterweight.

Think about what's missing. The community's interest in fiscal discipline, in rigorous scrutiny of capital spending, in questioning whether existing resources are fully utilized before approving new ones -- that interest has no persistent voice in the room. Taxpayers don't attend board meetings. They don't have the expertise to challenge clinical claims even if they did. The people who do show up, who do have expertise, and who do have a persistent voice are staff, physicians, and their advocates. All of them, quite naturally, argue for more resources.

The usual remedies are weak. Term limits for commissioners replace captured people with naive ones who will be captured in turn. Outside consultants are expensive and episodic. Investigative journalism at the local level has largely disappeared. Community attendance at board meetings is close to zero. None of these address the structural gap.

## A different kind of AI question

Most of the conversation about AI in healthcare right now is about tools for existing power groups. AI scribes for physicians. AI scheduling for administrators. AI documentation for nurses. These are useful. They are also extensions of the current structure -- making each group more efficient within the system as it already operates.

I've been wondering about a different question. What if AI's most important role in governance isn't serving the institution, but representing the people the institution is supposed to serve?

Imagine an AI participant in that board meeting -- not as a tool for the CEO's office, but as an analytical voice for the community interest. It could hold institutional memory across years of meetings, tracking whether past justifications for spending actually materialized as promised. It could cross-reference utilization data in real time when departments claim they need more capacity. It could ask the question nobody wants to ask: "The cath lab is empty 75% of the week. Can we talk about that before we talk about building more space?"

Such a system would not be subject to the social pressures that drive co-optation. It would have no interest in maintaining comfortable relationships with the CEO. It would not defer to a cardiologist's authority on matters of scheduling and utilization. It would not unconsciously converge on the answer that keeps everyone happy.

I want to be careful here. I'm saying "could," not "will." The technical capability is arguably close to existing today. The political problem is harder: such a system would need to be sanctioned by the very groups whose claims it would challenge. That is a real obstacle. And AI brings its own risks -- overconfidence in data, inability to read a room, potential for mechanistic thinking in situations that require judgment.

But the current situation is not working well enough. Good people, acting in good faith, reliably producing outcomes that don't serve the community as well as they should. That is a system problem. And system problems call for structural solutions.

I don't have a complete answer. I do have an interest in experimenting with this idea -- building analytical tools that could give commissioners an independent basis for evaluating the claims made to them. Not replacing human judgment, but informing it with the kind of persistent, dispassionate analysis that no part-time volunteer board member can sustain on their own.

I could be wrong about this. I welcome the pushback as much as the agreement. If you're involved in hospital governance, public or private, and this matches or contradicts what you see, I'd like to hear about it. You can reach me at john@common-sense.com.

---

[^1]: Philip Selznick, _TVA and the Grass Roots: A Study in the Sociology of Formal Organization_ (Berkeley: University of California Press, 1949).

[^2]: Selznick's definition as cited in the _Oxford Dictionary of Sociology_ and subsequent scholarship. For a recent retrospective, see Michael Hibbard and Kathryn Frank, "TVA and the Grass Roots at 75: The Legacy of a Planning Classic," _Journal of Planning Education and Research_ (2024).

[^3]: For principal-agent dynamics in healthcare governance specifically, see Derick Brinkerhoff and Thomas Bossert, "Health Governance: Principal-Agent Linkages and Health System Strengthening," _Health Policy and Planning_ 29, no. 6 (2014): 685-93.

[^4]: Eliyahu M. Goldratt, _It's Not Luck_ (Great Barrington, MA: North River Press, 1994). The principle recurs throughout Goldratt's body of work, particularly in his framing of Evaporating Clouds as tools for resolving system conflicts without compromise.
